name: CI

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

on:
  push:
    branches:
      - main
      - 'feature/**'
      - 'codex/**'
    tags:
      - 'v*.*.*'
  pull_request:
    branches:
      - main
  workflow_dispatch:
    inputs:
      run_uploader:
        description: 'Run the optional release uploader'
        required: false
        default: false
        type: boolean
      fix_version:
        description: 'Fix version to use when running the uploader'
        required: false
        type: string

permissions:
  contents: write
  pull-requests: write

jobs:
  lint:
    name: Lint (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    env:
      PRE_COMMIT_HOME: ~/.cache/pre-commit
      PYTHONPATH: ${{ github.workspace }}
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.10', '3.11']
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.event_name == 'pull_request' && github.head_ref || github.ref }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ matrix.python-version }}-${{ hashFiles('requirements*.txt', 'pyproject.toml') }}
          restore-keys: |
            pip-${{ runner.os }}-${{ matrix.python-version }}-

      - name: Cache pre-commit
        uses: actions/cache@v4
        with:
          path: ~/.cache/pre-commit
          key: pre-commit-${{ runner.os }}-${{ matrix.python-version }}-${{ hashFiles('.pre-commit-config.yaml', 'pyproject.toml') }}
          restore-keys: |
            pre-commit-${{ runner.os }}-${{ matrix.python-version }}-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip wheel
          if python - <<'PY'
            from __future__ import annotations

            import configparser
            from pathlib import Path


            def has_dev_extra() -> bool:
                pyproject = Path("pyproject.toml")
                if pyproject.is_file():
                    text = pyproject.read_text(encoding="utf-8")
                    try:
                        import tomllib  # type: ignore[attr-defined]
                    except ModuleNotFoundError:  # pragma: no cover - Python 3.10 fallback
                        tomllib = None  # type: ignore[assignment]
                    if tomllib is not None:
                        data = tomllib.loads(text)  # type: ignore[attr-defined]
                        extras = data.get("project", {}).get("optional-dependencies", {})
                        if "dev" in extras:
                            return True
                    if "[project.optional-dependencies]" in text and "dev" in text:
                        return True

                setup_cfg = Path("setup.cfg")
                if setup_cfg.is_file():
                    parser = configparser.ConfigParser()
                    parser.read(setup_cfg)
                    if parser.has_option("options.extras_require", "dev"):
                        return True

                return False


            raise SystemExit(0 if has_dev_extra() else 1)
          PY
          then
            pip install -e .[dev]
          else
            pip install -e .
            if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi
          fi

      - name: Run lint suite (check-only)
        run: scripts/ci/run_precommit.sh
        shell: bash

      - name: Verify clean working tree after linting
        run: |
          if ! git diff --quiet; then
            echo "Linting produced changes even though CI runs check-only." >&2
            echo "Run 'pre-commit run --all-files' locally or wait for pre-commit.ci to push fixes." >&2
            git status
            exit 1
          fi

  tests:
    name: Tests (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    needs: lint
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.10', '3.11']
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.event_name == 'pull_request' && github.head_ref || github.ref }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ matrix.python-version }}-${{ hashFiles('requirements*.txt', 'pyproject.toml') }}
          restore-keys: |
            pip-${{ runner.os }}-${{ matrix.python-version }}-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip wheel
          if python - <<'PY'
            from __future__ import annotations

            import configparser
            from pathlib import Path


            def has_dev_extra() -> bool:
                pyproject = Path("pyproject.toml")
                if pyproject.is_file():
                    text = pyproject.read_text(encoding="utf-8")
                    try:
                        import tomllib  # type: ignore[attr-defined]
                    except ModuleNotFoundError:  # pragma: no cover - Python 3.10 fallback
                        tomllib = None  # type: ignore[assignment]
                    if tomllib is not None:
                        data = tomllib.loads(text)  # type: ignore[attr-defined]
                        extras = data.get("project", {}).get("optional-dependencies", {})
                        if "dev" in extras:
                            return True
                    if "[project.optional-dependencies]" in text and "dev" in text:
                        return True

                setup_cfg = Path("setup.cfg")
                if setup_cfg.is_file():
                    parser = configparser.ConfigParser()
                    parser.read(setup_cfg)
                    if parser.has_option("options.extras_require", "dev"):
                        return True

                return False


            raise SystemExit(0 if has_dev_extra() else 1)
          PY
          then
            pip install -e .[dev]
          else
            pip install -e .
            if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi
          fi

      - name: Cache pytest
        uses: actions/cache@v4
        with:
          path: .pytest_cache
          key: pytest-${{ runner.os }}-${{ matrix.python-version }}-${{ hashFiles('pyproject.toml') }}

      - name: Determine coverage scope
        run: |
          set -eo pipefail
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            base=${{ github.event.pull_request.base.sha }}
          else
            base=${{ github.event.before }}
          fi
          if [ -z "$base" ]; then
            base=$(git rev-parse HEAD^)
          fi
          git fetch --no-tags --depth=1 origin "$base" || true
          git diff --name-only "$base" "$GITHUB_SHA" -- '*.py' > coverage_paths.txt
          python - <<'PY'
          import os
          from pathlib import Path

          paths = Path('coverage_paths.txt').read_text().split()
          value = ' '.join(paths)
          with open(os.environ['GITHUB_ENV'], 'a', encoding='utf-8') as env:
              env.write(f'COVERAGE_PATHS={value}\n')
          PY

      - name: Run pytest with coverage gate
        run: |
          pytest
          if [ -n "$COVERAGE_PATHS" ]; then
            python tools/coverage_gate.py coverage.json --paths $COVERAGE_PATHS
          else
            python tools/coverage_gate.py coverage.json
          fi

      - name: Coverage PR comment
        if: ${{ github.event_name == 'pull_request' && matrix.python-version == '3.11' }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          if [ -n "$COVERAGE_PATHS" ]; then
            python -m releasecopilot.cli pr-comment coverage --file coverage.json --paths $COVERAGE_PATHS
          else
            python -m releasecopilot.cli pr-comment coverage --file coverage.json
          fi

      - name: Upload coverage reports
        if: ${{ matrix.python-version == '3.11' }}
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ github.run_id }}
          path: |
            coverage.json
            coverage.xml
          if-no-files-found: error

  package:
    name: Package Lambda bundle
    runs-on: ubuntu-latest
    needs: tests
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: |
            requirements.txt
            requirements-dev.txt

      - name: Install build dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt -r requirements-dev.txt

      - name: Build Lambda bundle
        run: |
          set -euo pipefail
          mkdir -p dist
          if [ -f scripts/package_lambda.py ]; then
            python scripts/package_lambda.py --out dist/lambda_bundle.zip
          elif [ -f scripts/package_lambda.sh ]; then
            bash scripts/package_lambda.sh
            cd dist
            rm -f lambda_bundle.zip
            if [ -d lambda ]; then
              zip -r lambda_bundle.zip lambda
            else
              echo "Expected dist/lambda directory to exist after package script" >&2
              exit 1
            fi
          else
            echo "No packaging helper found; creating fallback archive" >&2
            rm -f dist/lambda_bundle.zip
            zip -r dist/lambda_bundle.zip aws clients config exporters processors main.py
          fi

      - name: Verify Lambda bundle artifact
        run: test -s dist/lambda_bundle.zip

      - name: Upload Lambda bundle artifact
        if: ${{ github.event_name != 'workflow_dispatch' }}
        uses: actions/upload-artifact@v4
        with:
          name: lambda_bundle
          path: dist/lambda_bundle.zip
          if-no-files-found: error
          retention-days: ${{ startsWith(github.ref, 'refs/tags/') && 30 || 7 }}

  cdk-synth:
    name: CDK synth
    runs-on: ubuntu-latest
    needs: tests
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: |
            requirements.txt
            infra/cdk/requirements.txt

      - name: Create virtual environment and install dependencies
        run: |
          python -m venv .venv
          source .venv/bin/activate
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          pip install -r infra/cdk/requirements.txt
        shell: bash

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'

      - name: Verify Node.js runtime
        run: node --version

      - name: Install AWS CDK
        run: npm install -g aws-cdk@2

      - name: Diagnose working dir & cdk.json
        run: |
          set -xeuo pipefail
          echo "PWD=$(pwd)"
          ls -la
          echo '--- cdk.json ---'
          test -f cdk.json && cat cdk.json || echo 'NO ROOT cdk.json FOUND'

      - name: Synthesize CDK app (root, explicit app)
        run: |
          source .venv/bin/activate
          npx cdk synth -a "python -m infra.cdk.app"
        shell: bash

  optional-uploader:
    name: Optional release uploader
    if: ${{ github.event_name == 'workflow_dispatch' && inputs.run_uploader == true }}
    runs-on: ubuntu-latest
    needs: [package]
    permissions:
      contents: read
      id-token: write
    env:
      AWS_REGION: ${{ vars.AWS_REGION || 'us-west-2' }}
      RC_S3_BUCKET: ${{ secrets.RC_S3_BUCKET }}
      RC_S3_PREFIX: releasecopilot
      FIX_VERSION: ${{ inputs.fix_version }}
      PYTHONPATH: src
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: |
            requirements.txt
            requirements-optional.txt

      - name: Install uploader dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          if [ -f requirements-optional.txt ]; then pip install -r requirements-optional.txt; fi

      - name: Compute OIDC availability flags
        env:
          ROLE: ${{ secrets.AWS_ROLE_TO_ASSUME }}
        run: |
          if [ -n "$ROLE" ]; then
            echo "AWS_ROLE_TO_ASSUME=$ROLE" >> "$GITHUB_ENV"
            echo "OIDC_PRESENT=true" >> "$GITHUB_ENV"
          else
            echo "OIDC_PRESENT=false" >> "$GITHUB_ENV"
          fi

      - name: Configure AWS credentials (OIDC)
        if: ${{ env.OIDC_PRESENT == 'true' }}
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Resolve fix version and run uploader
        env:
          GIT_REF_TYPE: ${{ github.ref_type }}
          GIT_REF_NAME: ${{ github.ref_name }}
        run: |
          if [ -z "$FIX_VERSION" ]; then
            if [ "$GIT_REF_TYPE" = "tag" ]; then
              FIX_VERSION="$GIT_REF_NAME"
            else
              FIX_VERSION="$(date +%Y.%m.%d)"
            fi
          fi

          if [ -z "$RC_S3_BUCKET" ]; then
            echo "RC_S3_BUCKET not set; skipping upload." >&2
            exit 0
          fi

          python -m releasecopilot.cli \
            --fix-version "$FIX_VERSION" \
            --s3-bucket "$RC_S3_BUCKET" \
            --s3-prefix "$RC_S3_PREFIX"
        shell: bash
