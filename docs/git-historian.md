# Git Historian (How to Run)

The Git Historian generates weekly (and on-demand) check-ins that summarize project momentum for Release Copilot.
This guide explains how to run the generator locally, how the scheduled GitHub Action works, and how to customize the
output for your team.

## Prerequisites

* Python 3.10+
* `requests` (installed automatically when you run `pip install -r requirements.txt`)
* A GitHub token with `repo` scope when running outside GitHub Actions. Export it as `GITHUB_TOKEN`.
* Optional integrations:
  * `HISTORIAN_ENABLE_JIRA=true` with relevant Jira credentials for linking stories to commits.
  * `HISTORIAN_ENABLE_S3_ARTIFACTS=true` to include S3 report locations in the check-in.
  * `HISTORIAN_ENABLE_HASH=true` to render sha256 hashes alongside artifacts (requires hashes in the artifact data).

## Running Locally

```bash
# Activate your virtual environment and install dependencies if needed
pip install -r requirements.txt

# Generate a history snapshot from the last 7 days
export GITHUB_TOKEN=<your-token>
python scripts/generate_history.py --since 7d --output docs/history
```

* The script creates `docs/history/YYYY-MM-DD-checkin.md` using [`docs/history/HISTORY_TEMPLATE.md`](history/HISTORY_TEMPLATE.md).
* Use `--since` with ISO timestamps (`2025-01-01T00:00:00Z`) or relative windows (`14d`, `48h`).
* Use `--repo owner/name` to override automatic repository detection.
* Set `--artifacts-file` to point to a JSON file describing build artifacts (see below).

### Artifact JSON Format

Provide artifact metadata in JSON using the following structure:

```json
{
  "artifacts": [
    {
      "name": "Weekly Export",
      "s3_key": "s3://my-bucket/exports/2025-02-14.csv",
      "hash": "<optional sha256 hash>"
    }
  ]
}
```

Artifacts are listed in the **Artifacts & Traceability** section. Hashes are displayed only when
`HISTORIAN_ENABLE_HASH=true` (or `--include-hash` is passed).

## GitHub Action (Scheduled + Manual)

The workflow in [`.github/workflows/weekly-history.yml`](../.github/workflows/weekly-history.yml) runs every Monday at 14:00 UTC
and can also be triggered manually (`workflow_dispatch`). It performs the following steps:

1. Check out the repository.
2. Run `python scripts/generate_history.py --since 7d --output docs/history`.
3. Commit changes in `docs/history/*.md` on a branch named `auto/history-<date>`.
4. Open a pull request summarizing the update.

If no files change, the workflow exits early and does not create a PR.

To run the workflow manually:

1. Navigate to **Actions → Weekly Git Historian** in GitHub.
2. Click **Run workflow** and optionally override the `since` window or template path.
3. A pull request is created automatically if new history content is generated.

## Customization

* **Template** – Pass `--template <path>` to the script to point to a custom Markdown template.
* **Sections** – The generator supports toggling Jira and artifact enrichment via environment variables or CLI flags.
* **Jira Linkage** – When `HISTORIAN_ENABLE_JIRA=true` and Jira credentials are configured, issues matching the configured
  JQL query are matched to commits using a regex (default: `[A-Z]+-\d+`). See the script docstring for configuration details.
* **Artifacts** – Provide artifact JSON files generated by your CI/CD system. You can also set `HISTORIAN_ARTIFACTS_FILE`
  to avoid passing the flag every time.
* **Dry Runs** – Use `--dry-run` to print the generated Markdown to stdout without writing a file.

## Troubleshooting

* Ensure `GITHUB_TOKEN` is available; unauthenticated calls are heavily rate limited.
* Use `--log-level DEBUG` for verbose output when debugging API calls.
* If you rely on Jira, confirm the `HISTORIAN_JIRA_*` variables are set and the JQL matches your workflow.
* Customize the schedule in the workflow by editing the cron expression in `weekly-history.yml`.

## Next Steps

* Link the generated check-ins from your Release Copilot dashboards or onboarding docs.
* Extend the generator to publish artifacts to S3 and pass the resulting manifest via `--artifacts-file`.
* Use the machine-readable index at `docs/context/context-index.json` (generated by the script) to support RAG pipelines.
