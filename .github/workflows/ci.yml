name: CI

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

on:
  push:
    branches:
      - main
      - 'feature/**'
      - 'codex/**'
    tags:
      - 'v*.*.*'
  pull_request:
    branches:
      - main
  workflow_dispatch:
    inputs:
      run_uploader:
        description: 'Run the optional release uploader'
        required: false
        default: false
        type: boolean
      fix_version:
        description: 'Fix version to use when running the uploader'
        required: false
        type: string
      run_import_autofix:
        description: 'Run Ruff autofix for import hygiene (E402/F404/I)'
        required: false
        default: false
        type: boolean

permissions:
  contents: write
  pull-requests: write

jobs:
  lint:
    name: Lint (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.10', '3.11']
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.event_name == 'pull_request' && github.head_ref || github.ref }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ matrix.python-version }}-${{ hashFiles('requirements*.txt', 'pyproject.toml') }}
          restore-keys: |
            pip-${{ runner.os }}-${{ matrix.python-version }}-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt -r requirements-dev.txt

      - name: Cache pre-commit
        uses: actions/cache@v4
        with:
          path: ~/.cache/pre-commit
          key: pre-commit-${{ runner.os }}-${{ matrix.python-version }}-${{ hashFiles('.pre-commit-config.yaml') }}
          restore-keys: |
            pre-commit-${{ runner.os }}-${{ matrix.python-version }}-

      - name: Ruff (optional import autofix)
        if: ${{ github.event_name == 'workflow_dispatch' && inputs.run_import_autofix == true }}
        run: |
          ruff check --output-format=github --select E402,F404,I --fix .
          ruff format .

      - name: Run pre-commit
        run: scripts/ci/run_precommit.sh
        shell: bash

      - name: Verify clean working tree after linting
        run: |
          if ! git diff --quiet; then
            echo "Linting produced changes after the auto-fix commit." >&2
            echo "Please run 'pre-commit run --all-files' locally before pushing." >&2
            git status
            exit 1
          fi

  typecheck:
    name: Type check
    runs-on: ubuntu-latest
    needs: lint
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-3.11-${{ hashFiles('requirements*.txt', 'pyproject.toml') }}
          restore-keys: |
            pip-${{ runner.os }}-3.11-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt -r requirements-dev.txt

      - name: Cache mypy
        uses: actions/cache@v4
        with:
          path: .mypy_cache
          key: mypy-${{ runner.os }}-${{ hashFiles('pyproject.toml') }}

      - name: Run mypy
        run: |
          mypy -p releasecopilot -p cli -p clients

  tests:
    name: Tests (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    needs: [lint, typecheck]
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.10', '3.11']
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.event_name == 'pull_request' && github.head_ref || github.ref }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ matrix.python-version }}-${{ hashFiles('requirements*.txt', 'pyproject.toml') }}
          restore-keys: |
            pip-${{ runner.os }}-${{ matrix.python-version }}-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt -r requirements-dev.txt

      - name: Cache pytest
        uses: actions/cache@v4
        with:
          path: .pytest_cache
          key: pytest-${{ runner.os }}-${{ matrix.python-version }}-${{ hashFiles('pyproject.toml') }}

      - name: Determine coverage scope
        run: |
          set -eo pipefail
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            base=${{ github.event.pull_request.base.sha }}
          else
            base=${{ github.event.before }}
          fi
          if [ -z "$base" ]; then
            base=$(git rev-parse HEAD^)
          fi
          git fetch --no-tags --depth=1 origin "$base" || true
          git diff --name-only "$base" "$GITHUB_SHA" -- '*.py' > coverage_paths.txt
          python - <<'PY'
          import os
          from pathlib import Path

          paths = Path('coverage_paths.txt').read_text().split()
          value = ' '.join(paths)
          with open(os.environ['GITHUB_ENV'], 'a', encoding='utf-8') as env:
              env.write(f'COVERAGE_PATHS={value}\n')
          PY

      - name: Run pytest with coverage gate
        run: |
          pytest
          if [ -n "$COVERAGE_PATHS" ]; then
            python tools/coverage_gate.py coverage.json --minimum 70 --paths $COVERAGE_PATHS
          else
            python tools/coverage_gate.py coverage.json --minimum 70
          fi

      - name: Coverage PR comment
        if: ${{ github.event_name == 'pull_request' && matrix.python-version == '3.11' }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          if [ -n "$COVERAGE_PATHS" ]; then
            python -m releasecopilot.cli pr-comment coverage --file coverage.json --minimum 70 --paths $COVERAGE_PATHS
          else
            python -m releasecopilot.cli pr-comment coverage --file coverage.json --minimum 70
          fi

      - name: Upload coverage reports
        if: ${{ matrix.python-version == '3.11' }}
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ github.run_id }}
          path: |
            coverage.json
            coverage.xml
          if-no-files-found: error

  package:
    name: Package Lambda bundle
    runs-on: ubuntu-latest
    needs: tests
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: |
            requirements.txt
            requirements-dev.txt

      - name: Install build dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt -r requirements-dev.txt

      - name: Build Lambda bundle
        run: |
          set -euo pipefail
          mkdir -p dist
          if [ -f scripts/package_lambda.py ]; then
            python scripts/package_lambda.py --out dist/lambda_bundle.zip
          elif [ -f scripts/package_lambda.sh ]; then
            bash scripts/package_lambda.sh
            cd dist
            rm -f lambda_bundle.zip
            if [ -d lambda ]; then
              zip -r lambda_bundle.zip lambda
            else
              echo "Expected dist/lambda directory to exist after package script" >&2
              exit 1
            fi
          else
            echo "No packaging helper found; creating fallback archive" >&2
            rm -f dist/lambda_bundle.zip
            zip -r dist/lambda_bundle.zip aws clients config exporters processors main.py
          fi

      - name: Verify Lambda bundle artifact
        run: test -s dist/lambda_bundle.zip

      - name: Upload Lambda bundle artifact
        if: ${{ github.event_name != 'workflow_dispatch' }}
        uses: actions/upload-artifact@v4
        with:
          name: lambda_bundle
          path: dist/lambda_bundle.zip
          if-no-files-found: error
          retention-days: ${{ startsWith(github.ref, 'refs/tags/') && 30 || 7 }}

  cdk-synth:
    name: CDK synth
    runs-on: ubuntu-latest
    needs: tests
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: |
            requirements.txt
            infra/cdk/requirements.txt

      - name: Create virtual environment and install dependencies
        run: |
          python -m venv .venv
          source .venv/bin/activate
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          pip install -r infra/cdk/requirements.txt
        shell: bash

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'

      - name: Verify Node.js runtime
        run: node --version

      - name: Install AWS CDK
        run: npm install -g aws-cdk@2

      - name: Diagnose working dir & cdk.json
        run: |
          set -xeuo pipefail
          echo "PWD=$(pwd)"
          ls -la
          echo '--- cdk.json ---'
          test -f cdk.json && cat cdk.json || echo 'NO ROOT cdk.json FOUND'

      - name: Synthesize CDK app (root, explicit app)
        run: |
          source .venv/bin/activate
          npx cdk synth -a "python -m infra.cdk.app"
        shell: bash

  optional-uploader:
    name: Optional release uploader
    if: ${{ github.event_name == 'workflow_dispatch' && inputs.run_uploader == true }}
    runs-on: ubuntu-latest
    needs: [package]
    permissions:
      contents: read
      id-token: write
    env:
      AWS_REGION: ${{ vars.AWS_REGION || 'us-west-2' }}
      RC_S3_BUCKET: ${{ secrets.RC_S3_BUCKET }}
      RC_S3_PREFIX: releasecopilot
      FIX_VERSION: ${{ inputs.fix_version }}
      PYTHONPATH: src
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: |
            requirements.txt
            requirements-optional.txt

      - name: Install uploader dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          if [ -f requirements-optional.txt ]; then pip install -r requirements-optional.txt; fi

      - name: Compute OIDC availability flags
        env:
          ROLE: ${{ secrets.AWS_ROLE_TO_ASSUME }}
        run: |
          if [ -n "$ROLE" ]; then
            echo "AWS_ROLE_TO_ASSUME=$ROLE" >> "$GITHUB_ENV"
            echo "OIDC_PRESENT=true" >> "$GITHUB_ENV"
          else
            echo "OIDC_PRESENT=false" >> "$GITHUB_ENV"
          fi

      - name: Configure AWS credentials (OIDC)
        if: ${{ env.OIDC_PRESENT == 'true' }}
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Resolve fix version and run uploader
        env:
          GIT_REF_TYPE: ${{ github.ref_type }}
          GIT_REF_NAME: ${{ github.ref_name }}
        run: |
          if [ -z "$FIX_VERSION" ]; then
            if [ "$GIT_REF_TYPE" = "tag" ]; then
              FIX_VERSION="$GIT_REF_NAME"
            else
              FIX_VERSION="$(date +%Y.%m.%d)"
            fi
          fi

          if [ -z "$RC_S3_BUCKET" ]; then
            echo "RC_S3_BUCKET not set; skipping upload." >&2
            exit 0
          fi

          python -m releasecopilot.cli \
            --fix-version "$FIX_VERSION" \
            --s3-bucket "$RC_S3_BUCKET" \
            --s3-prefix "$RC_S3_PREFIX"
        shell: bash
